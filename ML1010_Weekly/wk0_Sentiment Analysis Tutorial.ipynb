{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pn8fyGevt62D"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XmHgvt15t48a"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "PROJECT_NAME = 'ML1010_Weekly'\n",
    "ENABLE_COLAB = False\n",
    "\n",
    "#Root Machine Learning Directory. Projects appear underneath\n",
    "GOOGLE_DRIVE_MOUNT = '/content/gdrive' \n",
    "COLAB_ROOT_DIR = GOOGLE_DRIVE_MOUNT + '/MyDrive/Colab Notebooks'\n",
    "COLAB_INIT_DIR = COLAB_ROOT_DIR + '/utility_files'\n",
    "\n",
    "LOCAL_ROOT_DIR = '/home/magni/ML_Root/project_root'\n",
    "LOCAL_INIT_DIR = LOCAL_ROOT_DIR + '/utility_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QZKvJBJ7rlc"
   },
   "source": [
    "# Bootstrap Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17694,
     "status": "ok",
     "timestamp": 1638578131302,
     "user": {
      "displayName": "Michael Vasiliou",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07079983815732559270"
     },
     "user_tz": 300
    },
    "id": "jgMPxKZBzfFw",
    "outputId": "f49b4c4c-d1cd-44b5-d5fd-22abcd77e6d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wha...where am I?\n",
      "I am awake now.\n",
      "\n",
      "I have set your current working directory to /home/magni/ML_Root/project_root/ML1010_Weekly\n",
      "The current time is 12:43\n",
      "Hello sir. Extra caffeine may help.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#add in support for utility file directory and importing\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if ENABLE_COLAB:\n",
    "  #Need access to drive\n",
    "  from google.colab import drive\n",
    "  drive.mount(GOOGLE_DRIVE_MOUNT, force_remount=True)\n",
    "  \n",
    "  #add in utility directory to syspath to import \n",
    "  INIT_DIR = COLAB_INIT_DIR\n",
    "  sys.path.append(os.path.abspath(INIT_DIR))\n",
    "  \n",
    "  #Config environment variables\n",
    "  ROOT_DIR = COLAB_ROOT_DIR\n",
    "  \n",
    "else:\n",
    "  #add in utility directory to syspath to import\n",
    "  INIT_DIR = LOCAL_INIT_DIR\n",
    "  sys.path.append(os.path.abspath(INIT_DIR))\n",
    "  \n",
    "  #Config environment variables\n",
    "  ROOT_DIR = LOCAL_ROOT_DIR\n",
    "\n",
    "#Import Utility Support\n",
    "from jarvis import Jarvis\n",
    "jarvis = Jarvis(ROOT_DIR, PROJECT_NAME)\n",
    "\n",
    "import mv_python_utils as mvutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rastBhQqWt6Z"
   },
   "source": [
    "# Emotion and Sentiment Analysis\n",
    "Sentiment analysis is perhaps one of the most popular applications of NLP, with a vast number of tutorials, courses, and applications that focus on analyzing sentiments of diverse datasets ranging from corporate surveys to movie reviews. The key aspect of sentiment analysis is to analyze a body of text for understanding the opinion expressed by it. Typically, we quantify this sentiment with a positive or negative value, called polarity. The overall sentiment is often inferred as positive, neutral or negative from the sign of the polarity score.\n",
    "\n",
    "Usually, sentiment analysis works best on text that has a subjective context than on text with only an objective context. Objective text usually depicts some normal statements or facts without expressing any emotion, feelings, or mood. Subjective text contains text that is usually expressed by a human having typical moods, emotions, and feelings. Sentiment analysis is widely used, especially as a part of social media analysis for any domain, be it a business, a recent movie, or a product launch, to understand its reception by the people and what they think of it based on their opinions or, you guessed it, sentiment!\n",
    "\n",
    "\n",
    "Typically, sentiment analysis for text data can be computed on several levels, including on an individual sentence level, paragraph level, or the entire document as a whole. Often, sentiment is computed on the document as a whole or some aggregations are done after computing the sentiment for individual sentences. There are two major approaches to sentiment analysis.\n",
    " - Supervised machine learning or deep learning approaches\n",
    " - Unsupervised lexicon-based approaches\n",
    "\n",
    "For the first approach we typically need pre-labeled data. Hence, we will be focusing on the second approach. For a comprehensive coverage of sentiment analysis, refer to Chapter 7: Analyzing Movie Reviews Sentiment, Practical Machine Learning with Python, Springer\\Apress, 2018. In this scenario, we do not have the convenience of a well-labeled training dataset. Hence, we will need to use unsupervised techniques for predicting the sentiment by using knowledgebases, ontologies, databases, and lexicons that have detailed information, specially curated and prepared just for sentiment analysis. A lexicon is a dictionary, vocabulary, or a book of words. In our case, lexicons are special dictionaries or vocabularies that have been created for analyzing sentiments. Most of these lexicons have a list of positive and negative polar words with some score associated with them, and using various techniques like the position of words, surrounding words, context, parts of speech, phrases, and so on, scores are assigned to the text documents for which we want to compute the sentiment. After aggregating these scores, we get the final sentiment.\n",
    "\n",
    "\n",
    "Various popular lexicons are used for sentiment analysis, including the following.\n",
    "\n",
    "AFINN lexicon\n",
    "Bing Liu’s lexicon\n",
    "MPQA subjectivity lexicon\n",
    "SentiWordNet\n",
    "VADER lexicon\n",
    "TextBlob lexicon\n",
    "This is not an exhaustive list of lexicons that can be leveraged for sentiment analysis, and there are several other lexicons which can be easily obtained from the Internet. Feel free to check out each of these links and explore them. We will be covering two techniques in this section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TId0RLP3Wt6g"
   },
   "source": [
    "# Some Pre-Processing\n",
    "\n",
    "### Import necessary depencencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "c5x8AchnWt6h"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import model_evaluation_utils as meu\n",
    "\n",
    "np.set_printoptions(precision=2, linewidth=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5824,
     "status": "ok",
     "timestamp": 1638578146383,
     "user": {
      "displayName": "Michael Vasiliou",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07079983815732559270"
     },
     "user_tz": 300
    },
    "id": "CU75RBowX40Z",
    "outputId": "033e2dd6-66ed-4e7c-aa78-e42b1a485c36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Afinn\n",
      "  Downloading afinn-0.1.tar.gz (52 kB)\n",
      "     |████████████████████████████████| 52 kB 719 kB/s             \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: Afinn\n",
      "  Building wheel for Afinn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Afinn: filename=afinn-0.1-py3-none-any.whl size=53447 sha256=2f27c7961b123d0f29c5bdad80e304bba3ac22939cc0b55a6ef32628231aea14\n",
      "  Stored in directory: /home/magni/.cache/pip/wheels/9d/16/3a/9f0953027434eab5dadf3f33ab3298fa95afa8292fcf7aba75\n",
      "Successfully built Afinn\n",
      "Installing collected packages: Afinn\n",
      "Successfully installed Afinn-0.1\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/magni/python_env/ML1010_env2/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Afinn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuNoJbJbWt6j"
   },
   "source": [
    "### Load and normalize data\n",
    "1.  Cleaning Text - strip HTML\n",
    "2.  Removing accented characters\n",
    "3.  Expanding Contractions\n",
    "4.  Removing Special Characters\n",
    "5.  Lemmatizing text¶\n",
    "6.  Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uuv9iBtlWt6k"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(jarvis.DATA_DIR + '/movie_reviews_cleaned.csv')\n",
    "\n",
    "reviews = np.array(dataset['review'])\n",
    "sentiments = np.array(dataset['sentiment'])\n",
    "\n",
    "# extract data for model evaluation\n",
    "train_reviews = reviews[:35000]\n",
    "train_sentiments = sentiments[:35000]\n",
    "\n",
    "test_reviews = reviews[35000:]\n",
    "test_sentiments = sentiments[35000:]\n",
    "sample_review_ids = [7626, 3533, 13010]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UFRWM5-rWt6l",
    "outputId": "035b4288-492b-44db-80ca-52a3e10cde48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnorm_test_reviews = tn.normalize_corpus(test_reviews)\\nnorm_train_reviews = tn.normalize_corpus(train_reviews)\\n#output back to a csv file again\\nimport csv\\nwith open(r\\'movie_reviews_cleaned.csv\\', mode=\\'w\\') as cleaned_file:\\n    csv_writer = csv.writer(cleaned_file, delimiter=\\',\\', quotechar=\\'\"\\', quoting=csv.QUOTE_MINIMAL)\\n    csv_writer.writerow([\\'review\\', \\'sentiment\\'])\\n    for  text, sent in zip(norm_test_reviews, test_sentiments):\\n        csv_writer.writerow([text, sent])\\n    for  text, sent in zip(norm_train_reviews, train_sentiments):\\n        csv_writer.writerow([text, sent])\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SKIP FOR THE STUDENTS BECAUSE INSTRUCTOR HAS PRE_NORMALIZED AND SAVED THE FILE\n",
    "# normalize dataset (time consuming using spacey pipeline)\n",
    "\"\"\"\n",
    "norm_test_reviews = tn.normalize_corpus(test_reviews)\n",
    "norm_train_reviews = tn.normalize_corpus(train_reviews)\n",
    "#output back to a csv file again\n",
    "import csv\n",
    "with open(r'movie_reviews_cleaned.csv', mode='w') as cleaned_file:\n",
    "    csv_writer = csv.writer(cleaned_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(['review', 'sentiment'])\n",
    "    for  text, sent in zip(norm_test_reviews, test_sentiments):\n",
    "        csv_writer.writerow([text, sent])\n",
    "    for  text, sent in zip(norm_train_reviews, train_sentiments):\n",
    "        csv_writer.writerow([text, sent])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dmkyv7g2Wt6n"
   },
   "source": [
    "# ============================================\n",
    "# Part A. Unsupervised (Lexicon) Sentiment Analysis\n",
    "# ============================================\n",
    "## 1.  Sentiment Analysis with AFINN\n",
    "The AFINN lexicon is perhaps one of the simplest and most popular lexicons that can be used extensively for sentiment analysis. Developed and curated by Finn Arup Nielsen, you can find more details on this lexicon in the paper, “A new ANEW: evaluation of a word list for sentiment analysis in microblogs”, proceedings of the ESWC 2011 Workshop. The current version of the lexicon is AFINN-en-165. txt and it contains over 3,300+ words with a polarity score associated with each word. You can find this lexicon at the author’s official GitHub repository along with previous versions of it, including AFINN-111. The author has also created a nice wrapper library on top of this in Python called afinn, which we will be using for our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lFBu4U7yWt6o"
   },
   "outputs": [],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "afn = Afinn(emoticons=True) \n",
    "\n",
    "# NOTE:  to use afinn score, call the function afn.score(\"text you want the sentiment for\")\n",
    "# the lexicon will be used to compute summary of sentiment for the given text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NkP0qM6Wt6o"
   },
   "source": [
    "### Predict sentiment for sample reviews\n",
    "We can get a good idea of general sentiment for different sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 160,
     "status": "ok",
     "timestamp": 1638578165204,
     "user": {
      "displayName": "Michael Vasiliou",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07079983815732559270"
     },
     "user_tz": 300
    },
    "id": "bz1ehKVsWt6p",
    "outputId": "a53df84e-3675-454d-ff12-057a081656e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: word fail whenever want describe feeling movie sequel flaw sure start subspecie not execute well enough special effect glorify movie herd movie mass consumer care quantity quality cheap fun depth crap like blade not even deserve capital letter underworlddracula 2000dracula 3000 good movie munch popcorn drink couple coke make subspecie superior effort anyone claim vampire fanatic hand obvious vampire romanian story set transylvania scene film location convince atmosphere not base action pack chase expensive orchestral music radu source atmosphere vampire look like behave add breathtakingly gloomy castle dark passageway situate romania include typical vampiric element movement shadow wall vampire take flight work art short like fascinated vampire feel appearance well setting sinister dark no good place look subspecie movie vampire journal brilliant spin former\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment polarity: 20.0\n",
      "------------------------------------------------------------\n",
      "REVIEW: good family movie laugh wish not much school stuff like bully fill movie also seem little easy save piece land build mean flow easily make aware wildlife cute way introduce piece land fast runner little slow little hokey remind go back school oh dvd chock full goody not miss 7 10 movie 10 10 dvd extra well worth watch well worth time see\n",
      "Actual Sentiment: positive\n",
      "Predicted Sentiment polarity: 12.0\n",
      "------------------------------------------------------------\n",
      "REVIEW: opinion movie not good hardly find good thing say still would like explain conclude another bad movie decide watch costas mandylor star main reason watch till end like action movie understand movie build action rather story know not go detail come credibility story event even not explain scene lack sense reality look ridiculous beginning movie look quite promising tough good look specialist not tough smart funny partner must job turn bit different expect story take place cruise ship disaster happen ship turn leave alive struggle survive escape shark professional killer rise water furthermore movie quite violent main weapon beside disaster already take passenger gun successfully use many case personally miss good man man woman woman prefer fight family fun not think think movie shoot hurry without real vision try say make usual action movie trick bit something call love without real meaning result bad movie\n",
      "Actual Sentiment: negative\n",
      "Predicted Sentiment polarity: 2.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    print('Predicted Sentiment polarity:', afn.score(review))\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLIMjDDIWt6q"
   },
   "source": [
    "### Predict sentiment for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "BXqlGudHWt6r"
   },
   "outputs": [],
   "source": [
    "sentiment_polarity = [afn.score(review) for review in test_reviews]\n",
    "predicted_sentiments = ['positive' if score >= 1.0 else 'negative' for score in sentiment_polarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 145,
     "status": "ok",
     "timestamp": 1638578246503,
     "user": {
      "displayName": "Michael Vasiliou",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07079983815732559270"
     },
     "user_tz": 300
    },
    "id": "IR6LdMqCY0OS",
    "outputId": "f498d4fe-b894-4a5d-f8f7-53efd99b70c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n"
     ]
    }
   ],
   "source": [
    "display(type(sentiment_polarity))\n",
    "print(sentiment_polarity[4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zq5fzULCWt6r"
   },
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1638578251315,
     "user": {
      "displayName": "Michael Vasiliou",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07079983815732559270"
     },
     "user_tz": 300
    },
    "id": "R58ya-OwWt6s",
    "outputId": "749ef414-3794-42e3-a14a-630c085f02cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.56      0.65      7413\n",
      "    positive       0.66      0.84      0.74      7587\n",
      "\n",
      "    accuracy                           0.71     15000\n",
      "   macro avg       0.72      0.70      0.70     15000\n",
      "weighted avg       0.72      0.71      0.70     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "results = metrics.classification_report(test_sentiments, predicted_sentiments)\n",
    "print(results)\n",
    "\n",
    "#meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, \n",
    "#                                  classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2xNpcSvWt6s"
   },
   "source": [
    "## 2. Sentiment Analysis with SentiWordNet\n",
    "SentiWordNet is a lexical resource for opinion mining. SentiWordNet assigns to each synset of WordNet three sentiment scores: positivity, negativity, objectivity. SentiWordNet is described in details in the papers: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7nr_StKwWt6t",
    "outputId": "2363f735-7988-470c-c26c-ee8795e9ea07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/magni/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/magni/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/magni/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Polarity Score: 0.875\n",
      "Negative Polarity Score: 0.125\n",
      "Objective Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('sentiwordnet')\n",
    "\n",
    "awesome = list(swn.senti_synsets('awesome', 'a'))[0]\n",
    "print('Positive Polarity Score:', awesome.pos_score())\n",
    "print('Negative Polarity Score:', awesome.neg_score())\n",
    "print('Objective Score:', awesome.obj_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTYt2XbZWt6t"
   },
   "source": [
    "### Build model\n",
    "For each word in  the review, add up the sentiment score of words that are NN, VB, JJ, RB if it's in the lexicon dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "RPowkulJWt6t"
   },
   "outputs": [],
   "source": [
    "import text_normalizer as tn\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "def analyze_sentiment_sentiwordnet_lexicon(review,\n",
    "                                           verbose=False):\n",
    "\n",
    "    # tokenize and POS tag text tokens\n",
    "    tagged_text = [(token.text, token.tag_) for token in nlp(review)]\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    # get wordnet synsets based on POS tags\n",
    "    # get sentiment scores if synsets are found\n",
    "    for word, tag in tagged_text:\n",
    "        ss_set = None\n",
    "        if 'NN' in tag and list(swn.senti_synsets(word, 'n')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'n'))[0]\n",
    "        elif 'VB' in tag and list(swn.senti_synsets(word, 'v')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'v'))[0]\n",
    "        elif 'JJ' in tag and list(swn.senti_synsets(word, 'a')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'a'))[0]\n",
    "        elif 'RB' in tag and list(swn.senti_synsets(word, 'r')):\n",
    "            ss_set = list(swn.senti_synsets(word, 'r'))[0]\n",
    "        # if senti-synset is found        \n",
    "        if ss_set:\n",
    "            # add scores for all found synsets\n",
    "            pos_score += ss_set.pos_score()\n",
    "            neg_score += ss_set.neg_score()\n",
    "            obj_score += ss_set.obj_score()\n",
    "            token_count += 1\n",
    "    \n",
    "    # aggregate final scores\n",
    "    final_score = pos_score - neg_score\n",
    "    norm_final_score = round(float(final_score) / token_count, 2)\n",
    "    final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'\n",
    "    if verbose:\n",
    "        norm_obj_score = round(float(obj_score) / token_count, 2)\n",
    "        norm_pos_score = round(float(pos_score) / token_count, 2)\n",
    "        norm_neg_score = round(float(neg_score) / token_count, 2)\n",
    "        # to display results in a nice table\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, norm_obj_score, norm_pos_score, \n",
    "                                         norm_neg_score, norm_final_score]],\n",
    "                                       columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                             ['Predicted Sentiment', 'Objectivity',\n",
    "                                                              'Positive', 'Negative', 'Overall']], \n",
    "                                                             codes=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "        \n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HMb2vwoWt6u"
   },
   "source": [
    "### Predict sentiment for sample reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "JIon6MH7Wt6u",
    "outputId": "1f58674e-3b84-49dd-8a85-1496816e94f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: word fail whenever want describe feeling movie sequel flaw sure start subspecie not execute well enough special effect glorify movie herd movie mass consumer care quantity quality cheap fun depth crap like blade not even deserve capital letter underworlddracula 2000dracula 3000 good movie munch popcorn drink couple coke make subspecie superior effort anyone claim vampire fanatic hand obvious vampire romanian story set transylvania scene film location convince atmosphere not base action pack chase expensive orchestral music radu source atmosphere vampire look like behave add breathtakingly gloomy castle dark passageway situate romania include typical vampiric element movement shadow wall vampire take flight work art short like fascinated vampire feel appearance well setting sinister dark no good place look subspecie movie vampire journal brilliant spin former\n",
      "Actual Sentiment: positive\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.86     0.08     0.06    0.02\n",
      "------------------------------------------------------------\n",
      "REVIEW: good family movie laugh wish not much school stuff like bully fill movie also seem little easy save piece land build mean flow easily make aware wildlife cute way introduce piece land fast runner little slow little hokey remind go back school oh dvd chock full goody not miss 7 10 movie 10 10 dvd extra well worth watch well worth time see\n",
      "Actual Sentiment: positive\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.82     0.09     0.09     0.0\n",
      "------------------------------------------------------------\n",
      "REVIEW: opinion movie not good hardly find good thing say still would like explain conclude another bad movie decide watch costas mandylor star main reason watch till end like action movie understand movie build action rather story know not go detail come credibility story event even not explain scene lack sense reality look ridiculous beginning movie look quite promising tough good look specialist not tough smart funny partner must job turn bit different expect story take place cruise ship disaster happen ship turn leave alive struggle survive escape shark professional killer rise water furthermore movie quite violent main weapon beside disaster already take passenger gun successfully use many case personally miss good man man woman woman prefer fight family fun not think think movie shoot hurry without real vision try say make usual action movie trick bit something call love without real meaning result bad movie\n",
      "Actual Sentiment: negative\n",
      "     SENTIMENT STATS:                                      \n",
      "  Predicted Sentiment Objectivity Positive Negative Overall\n",
      "0            positive        0.82     0.09     0.09    -0.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    pred = analyze_sentiment_sentiwordnet_lexicon(review, verbose=True)    \n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4hgB-79Wt6v"
   },
   "source": [
    "### Predict sentiment for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "yZ4x_lUDWt6v"
   },
   "outputs": [],
   "source": [
    "predicted_sentiments = [analyze_sentiment_sentiwordnet_lexicon(review, verbose=False) for review in test_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tg-ryhP3Wt6w"
   },
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KwXAlYTAWt6w",
    "outputId": "1df9d32a-b6da-4641-b825-0179b5c4e344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.60      0.65      7413\n",
      "    positive       0.66      0.76      0.71      7587\n",
      "\n",
      "    accuracy                           0.68     15000\n",
      "   macro avg       0.69      0.68      0.68     15000\n",
      "weighted avg       0.69      0.68      0.68     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = metrics.classification_report(test_sentiments, predicted_sentiments)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hF0A8DfBWt6w"
   },
   "source": [
    "## 3. Sentiment Analysis with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Zn_YkEAoWt6x",
    "outputId": "bfb61942-e08c-4f6f-d9f3-3d64df3406c9"
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMTtF_HyWt6x"
   },
   "source": [
    "### Build model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.66-py2.py3-none-any.whl (8.0 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting pyahocorasick\n",
      "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
      "     |████████████████████████████████| 321 kB 4.0 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting anyascii\n",
      "  Downloading anyascii-0.3.0-py3-none-any.whl (284 kB)\n",
      "     |████████████████████████████████| 284 kB 10.1 MB/s            \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=91924 sha256=e60155a3c2fd5b8e97b0307ded9d030bc222ae04bcff6a3c3c605fb6a914c595\n",
      "  Stored in directory: /home/magni/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.0 contractions-0.1.66 pyahocorasick-1.4.2 textsearch-0.0.21\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/home/magni/python_env/ML1010_env2/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "-sZB3f6GWt6x"
   },
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader_lexicon(review, \n",
    "                                    threshold=0.1,\n",
    "                                    verbose=False):\n",
    "    # pre-process text\n",
    "    \n",
    "    #review = tn.strip(review)\n",
    "    #review = tn.remove_accented_chars(review)\n",
    "    #review = tn.expand_contractions(review)\n",
    "    \n",
    "    # analyze the sentiment for review\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    # get aggregate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 'positive' if agg_score >= threshold\\\n",
    "                                   else 'negative'\n",
    "    if verbose:\n",
    "        # display detailed sentiment statistics\n",
    "        positive = str(round(scores['pos'], 2)*100)+'%'\n",
    "        final = round(agg_score, 2)\n",
    "        negative = str(round(scores['neg'], 2)*100)+'%'\n",
    "        neutral = str(round(scores['neu'], 2)*100)+'%'\n",
    "        sentiment_frame = pd.DataFrame([[final_sentiment, final, positive,\n",
    "                                        negative, neutral]],\n",
    "                                        columns=pd.MultiIndex(levels=[['SENTIMENT STATS:'], \n",
    "                                                                      ['Predicted Sentiment', 'Polarity Score',\n",
    "                                                                       'Positive', 'Negative', 'Neutral']], \n",
    "                                                              codes=[[0,0,0,0,0],[0,1,2,3,4]]))\n",
    "        print(sentiment_frame)\n",
    "    \n",
    "    return final_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxMWPbd5Wt6y"
   },
   "source": [
    "### Predict sentiment for sample reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "y3zE31YcWt6y",
    "outputId": "f3f1e606-55fd-4a0f-d75f-9b6de706ffad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REVIEW: word fail whenever want describe feeling movie sequel flaw sure start subspecie not execute well enough special effect glorify movie herd movie mass consumer care quantity quality cheap fun depth crap like blade not even deserve capital letter underworlddracula 2000dracula 3000 good movie munch popcorn drink couple coke make subspecie superior effort anyone claim vampire fanatic hand obvious vampire romanian story set transylvania scene film location convince atmosphere not base action pack chase expensive orchestral music radu source atmosphere vampire look like behave add breathtakingly gloomy castle dark passageway situate romania include typical vampiric element movement shadow wall vampire take flight work art short like fascinated vampire feel appearance well setting sinister dark no good place look subspecie movie vampire journal brilliant spin former\n",
      "Actual Sentiment: positive\n",
      "     SENTIMENT STATS:                                                     \n",
      "  Predicted Sentiment Polarity Score             Positive Negative Neutral\n",
      "0            positive           0.98  28.000000000000004%    11.0%   61.0%\n",
      "------------------------------------------------------------\n",
      "REVIEW: good family movie laugh wish not much school stuff like bully fill movie also seem little easy save piece land build mean flow easily make aware wildlife cute way introduce piece land fast runner little slow little hokey remind go back school oh dvd chock full goody not miss 7 10 movie 10 10 dvd extra well worth watch well worth time see\n",
      "Actual Sentiment: positive\n",
      "     SENTIMENT STATS:                                                     \n",
      "  Predicted Sentiment Polarity Score Positive Negative             Neutral\n",
      "0            positive           0.97    39.0%     4.0%  57.99999999999999%\n",
      "------------------------------------------------------------\n",
      "REVIEW: opinion movie not good hardly find good thing say still would like explain conclude another bad movie decide watch costas mandylor star main reason watch till end like action movie understand movie build action rather story know not go detail come credibility story event even not explain scene lack sense reality look ridiculous beginning movie look quite promising tough good look specialist not tough smart funny partner must job turn bit different expect story take place cruise ship disaster happen ship turn leave alive struggle survive escape shark professional killer rise water furthermore movie quite violent main weapon beside disaster already take passenger gun successfully use many case personally miss good man man woman woman prefer fight family fun not think think movie shoot hurry without real vision try say make usual action movie trick bit something call love without real meaning result bad movie\n",
      "Actual Sentiment: negative\n",
      "     SENTIMENT STATS:                                                     \n",
      "  Predicted Sentiment Polarity Score Positive Negative             Neutral\n",
      "0            negative          -0.98    12.0%    31.0%  56.00000000000001%\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/magni/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "\n",
    "for review, sentiment in zip(test_reviews[sample_review_ids], test_sentiments[sample_review_ids]):\n",
    "    print('REVIEW:', review)\n",
    "    print('Actual Sentiment:', sentiment)\n",
    "    pred = analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=True)    \n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmVyFQbHWt6y"
   },
   "source": [
    "### Predict sentiment for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "5DYEKLhoWt6z"
   },
   "outputs": [],
   "source": [
    "predicted_sentiments = [analyze_sentiment_vader_lexicon(review, threshold=0.4, verbose=False) for review in test_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CW9aeguGWt6z"
   },
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "error",
     "timestamp": 1637680443877,
     "user": {
      "displayName": "Michael Vasiliou",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07079983815732559270"
     },
     "user_tz": 300
    },
    "id": "IV1oPGqZWt60",
    "outputId": "b7028238-b24b-4c8e-907e-45e3c15fb7a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.6964\n",
      "Precision: 0.704\n",
      "Recall: 0.6964\n",
      "F1 Score: 0.6929\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.67      0.80      0.73      7587\n",
      "    negative       0.74      0.59      0.66      7413\n",
      "\n",
      "    accuracy                           0.70     15000\n",
      "   macro avg       0.70      0.70      0.69     15000\n",
      "weighted avg       0.70      0.70      0.69     15000\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "                 Predicted:         \n",
      "                   positive negative\n",
      "Actual: positive       6066     1521\n",
      "        negative       3033     4380\n"
     ]
    }
   ],
   "source": [
    "import model_evaluation_utils as meu\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=predicted_sentiments, \n",
    "                                  classes=['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YiztHZ6nWt60"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "wk0_Sentiment Analysis Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ML1010_env2",
   "language": "python",
   "name": "ml1010_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
